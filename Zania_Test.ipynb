{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VQWtjw2dRyM",
        "outputId": "f237f8db-a04a-466a-8580-b0e580d67f24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.4-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Collecting PyMuPDFb==1.24.3 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: PyMuPDFb, h11, pymupdf, httpcore, httpx, openai\n",
            "Successfully installed PyMuPDFb-1.24.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3 pymupdf-1.24.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken slack_sdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43_lbwnjdfpB",
        "outputId": "b0399195-a5c6-4151-d6e3-3f9391715c2f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Collecting slack_sdk\n",
            "  Downloading slack_sdk-3.27.2-py2.py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.5/286.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: slack_sdk\n",
            "Successfully installed slack_sdk-3.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "import json\n",
        "import fitz\n",
        "import re\n",
        "import ast\n",
        "from scipy import spatial\n",
        "GPT_MODEL = \"gpt-3.5-turbo\"\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "from slack_sdk import WebClient\n",
        "client1 = WebClient(token=\"your_slack_token\")\n",
        "\n",
        "client = openai.OpenAI(api_key='your_open_ai_api_key')\n",
        "\n",
        "def send_to_slack(message):\n",
        "  result = client1.chat_postMessage(\n",
        "      channel='C04HA4VAMEU',\n",
        "      text=message\n",
        "  )\n",
        "\n",
        "\n",
        "def split_text(text):\n",
        "\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    return sentences\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text=''\n",
        "\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        #text[page_num]=page.get_text()\n",
        "        text+=page.get_text()\n",
        "    return text\n",
        "\n",
        "def strings_ranked_by_relatedness(\n",
        "    query: str,\n",
        "    df: pd.DataFrame,\n",
        "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
        "    top_n: int = 100\n",
        ") -> tuple[list[str], list[float]]:\n",
        "    query_embedding_response = client.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=query,\n",
        "    )\n",
        "    query_embedding = query_embedding_response.data[0].embedding\n",
        "\n",
        "    strings_and_relatednesses = [\n",
        "        (row[\"text\"], relatedness_fn(query_embedding, list(row[\"embedding\"])))\n",
        "        for i, row in df.iterrows()\n",
        "    ]\n",
        "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
        "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
        "    return strings[:top_n], relatednesses[:top_n]\n",
        "\n",
        "\n",
        "\n",
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "\n",
        "def query_message(\n",
        "    query: str,\n",
        "    df: pd.DataFrame,\n",
        "    model: str,\n",
        "    token_budget: int\n",
        ") -> str:\n",
        "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
        "    introduction = 'Use the below text to answer the subsequent question. If the answer cannot be found in the text, write \"I could not find an answer.\"'\n",
        "    question = f\"\\n\\nQuestion: {query}\"\n",
        "    message = introduction\n",
        "    for string in strings:\n",
        "        next_article = f'\\n\\nText Sentence\\n\"\"\"\\n{string}\\n\"\"\"'\n",
        "        if (\n",
        "            num_tokens(message + next_article + question, model=model)\n",
        "            > token_budget\n",
        "        ):\n",
        "            break\n",
        "        else:\n",
        "            message += next_article\n",
        "    return message + question\n",
        "\n",
        "\n",
        "def ask(\n",
        "    query: str,\n",
        "    df: pd.DataFrame,\n",
        "    model: str = GPT_MODEL,\n",
        "    token_budget: int = 4096 - 500,\n",
        "    print_message: bool = False,\n",
        ") -> str:\n",
        "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
        "    if print_message:\n",
        "        print(message)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You answer questions about the text\"},\n",
        "        {\"role\": \"user\", \"content\": message},\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    response_message = response.choices[0].message.content\n",
        "    return response_message\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def answering(pdf_doc,questions):\n",
        "    EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "    BATCH_SIZE = 1000\n",
        "    pdf_text=extract_text_from_pdf(pdf_doc)\n",
        "    pdf_text_list=split_text(pdf_text)\n",
        "\n",
        "    embeddings = []\n",
        "    for batch_start in range(0, len(pdf_text_list), BATCH_SIZE):\n",
        "        batch_end = batch_start + BATCH_SIZE\n",
        "        batch = pdf_text_list[batch_start:batch_end]\n",
        "        print(f\"Batch {batch_start} to {batch_end-1}\")\n",
        "        response = client.embeddings.create(model=EMBEDDING_MODEL, input=batch)\n",
        "        for i, be in enumerate(response.data):\n",
        "            assert i == be.index\n",
        "        batch_embeddings = [e.embedding for e in response.data]\n",
        "        embeddings.extend(batch_embeddings)\n",
        "\n",
        "    df = pd.DataFrame({\"text\": pdf_text_list, \"embedding\": embeddings})\n",
        "    print(df.head())\n",
        "    df.to_csv('handbook_pdf_embeddings.csv')\n",
        "    df=pd.read_csv('handbook_pdf_embeddings.csv')\n",
        "    df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df['embedding'] = df['embedding'].apply(ast.literal_eval)\n",
        "    answers=[]\n",
        "    for i in questions:\n",
        "      x=ask(i,df)\n",
        "      answers.append(x)\n",
        "    qa = dict(zip(questions, answers))\n",
        "    json_data = json.dumps(qa)\n",
        "\n",
        "    return json_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CmFfhTGPYs4k"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions=['What is the name of the company?',\n",
        "'Who is the CEO of the company?',\n",
        "'What is their vacation policy?',\n",
        "'What is the termination policy?'\n",
        "]\n",
        "\n",
        "output=answering('handbook.pdf',questions)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "nPNQNZjudd78",
        "outputId": "193ad38d-dc9b-4d90-b63d-4621206e3f4a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 to 999\n",
            "                                                text  \\\n",
            "0                                        Zania, Inc.   \n",
            "1  Zania Employee Handbook\\nSeptember 07, 2023\\nT...   \n",
            "2     You have just joined a dedicated organization.   \n",
            "3      We hope that your employment with Zania, Inc.   \n",
            "4                will be rewarding\\nand challenging.   \n",
            "\n",
            "                                           embedding  \n",
            "0  [0.017726914957165718, 0.046172428876161575, 0...  \n",
            "1  [0.02425610087811947, 0.010685230605304241, 0....  \n",
            "2  [0.011331990361213684, 0.000718834693543613, 0...  \n",
            "3  [0.02359427511692047, 0.04291785508394241, -0....  \n",
            "4  [0.013710535131394863, -0.006862619426101446, ...  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"What is the name of the company?\": \"The name of the company is Zania, Inc.\", \"Who is the CEO of the company?\": \"Shruti Gupta is the CEO of the company.\", \"What is their vacation policy?\": \"The vacation policy allows full-time regular employees to receive vacation time immediately upon hire, with the amount of vacation received each year based on length of service and granted in a lump sum at the beginning of each year. Employees may accrue a certain number of hours/days/weeks of vacation for every period worked, up to a maximum accrual amount. Unused vacation can be carried over to the following year or the company may offer payment for the unused time. Employees are encouraged to use their vacation time, and requests for vacation must be made in advance. Seniority may determine priority in scheduling vacation times, and unused vacation may be forfeited upon separation of employment unless state law dictates otherwise.\", \"What is the termination policy?\": \"The termination policy includes disciplinary action, up to and including termination of employment, for violations of company policies and procedures.\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "send_to_slack(output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dGZMy1_lZFVh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "Zkgc70502czc",
        "outputId": "02cd718f-9b6f-46f3-c448-82b028026d42"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"What is the name of the company?\": \"The name of the company is Zania, Inc.\", \"Who is the CEO of the company?\": \"Shruti Gupta is the CEO of the company.\", \"What is their vacation policy?\": \"The vacation policy allows full-time regular employees to receive vacation time immediately upon hire, with the amount of vacation received each year based on length of service and granted in a lump sum at the beginning of each year. Employees may accrue a certain number of hours/days/weeks of vacation for every period worked, up to a maximum accrual amount. Unused vacation can be carried over to the following year or the company may offer payment for the unused time. Employees are encouraged to use their vacation time, and requests for vacation must be made in advance. Seniority may determine priority in scheduling vacation times, and unused vacation may be forfeited upon separation of employment unless state law dictates otherwise.\", \"What is the termination policy?\": \"The termination policy includes disciplinary action, up to and including termination of employment, for violations of company policies and procedures.\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}